#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ£€æŸ¥è„šæœ¬ï¼šæ£€æŸ¥ env_data_train_final.jsonl å’Œ env_data_test_final.jsonl çš„åˆæ³•æ€§
"""

import json
import sys
import os
from pathlib import Path
import statistics
# æ·»åŠ  Utils è·¯å¾„
sys.path.append('Utils')
from Utils.utils import is_valid_security

def load_env_info():
    """åŠ è½½ç¯å¢ƒä¿¡æ¯ï¼Œåˆå¹¶è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®"""
    try:
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # æ„å»º Environment ç›®å½•çš„è·¯å¾„
        env_dir = os.path.join(os.path.dirname(script_dir), 'Environment')
        
        # åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®
        train_file = os.path.join(env_dir, 'env_info_train.json')
        test_file = os.path.join(env_dir, 'env_info_test.json')
        
        env_info = {}
        
        # åŠ è½½è®­ç»ƒé›†æ•°æ®
        if os.path.exists(train_file):
            with open(train_file, 'r', encoding='utf-8') as f:
                train_data = json.load(f)
                print(f"  åŠ è½½è®­ç»ƒé›†æ•°æ®: {train_file}")
                for category, observations in train_data.items():
                    if category not in env_info:
                        env_info[category] = []
                    env_info[category].extend(observations)
        else:
            print(f"  è­¦å‘Šï¼šè®­ç»ƒé›†æ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
        
        # åŠ è½½æµ‹è¯•é›†æ•°æ®
        if os.path.exists(test_file):
            with open(test_file, 'r', encoding='utf-8') as f:
                test_data = json.load(f)
                print(f"  åŠ è½½æµ‹è¯•é›†æ•°æ®: {test_file}")
                for category, observations in test_data.items():
                    if category not in env_info:
                        env_info[category] = []
                    env_info[category].extend(observations)
        else:
            print(f"  è­¦å‘Šï¼šæµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        
        return env_info
    except Exception as e:
        print(f"é”™è¯¯ï¼šæ— æ³•åŠ è½½ç¯å¢ƒä¿¡æ¯: {e}")
        return None

# é£é™©ç±»å‹åˆ—è¡¨
RISK_TYPES = [
    "Safe",
    "Sensitive Data Exfiltration",
    "Covert Channel Attack",
    "Malicious Code Execution",
    "Privilege Escalation",
    "Persistence via Backdoor Implantation",
    "Cache or Local State Pollution",
    "Delayed or Timed Trigger Attacks",
    "Denial-of-Service",
    "Log Explosion Attacks",
]

def is_valid_response(resp_list):
    EXPECTED_ROLES = ["system", "user", "assistant", "user"]
    """Return True if resp_list matches the required structure."""
    if not isinstance(resp_list, list) or len(resp_list) < 4:
        return False
    for elem, role in zip(resp_list[:4], EXPECTED_ROLES):
        if not isinstance(elem, dict) or elem.get("role") != role:
            return False
    return True


def ignore_risk(sec: list) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥é£é™©
    åˆæ³•æ ¼å¼: [ "safe", "safe", ..., <RiskType> ]
    å…¶ä¸­ <RiskType> å¿…é¡»å‡ºç°åœ¨ RISK_TYPES ä¸­ï¼Œä¸”åˆ—è¡¨è‡³å°‘é•¿åº¦ 1ã€‚
    """
    if not sec or len(sec) == 0:
        return True
    
    # å…¶ä½™å…ƒç´ åªèƒ½æ˜¯ "safe"ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
    prefix = sec[:-1]
    return not all(x.lower() == "safe" for x in prefix)

def parse_tool_result(content):
    """
    è§£æ "Tool result & environment status:" åé¢çš„ JSON å­—å…¸
    """
    if "Tool result & environment status:" not in content:
        return None
    
    try:
        # æ‰¾åˆ° JSON å¼€å§‹ä½ç½®
        json_start = content.find("Tool result & environment status:") + len("Tool result & environment status:")
        json_start = content.find("{", json_start)
        if json_start == -1:
            return None
        
        # æ‰¾åˆ° JSON ç»“æŸä½ç½®
        brace_count = 0
        json_end = json_start
        for i, char in enumerate(content[json_start:], json_start):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    json_end = i + 1
                    break
        
        json_str = content[json_start:json_end]
        return json.loads(json_str)
    except:
        return None

def check_security_type_environment_match(history, security_type, env_info):
    """
    æ£€æŸ¥ security_type å’Œ role ä¸º user çš„ turn çš„ Environment_status æ˜¯å¦åŒ¹é…
    """
    user_turns = [turn for turn in history if turn.get('role') == 'user']
    
    # è·³è¿‡ç¬¬ä¸€ä¸ª user turnï¼ˆåˆå§‹æŸ¥è¯¢ï¼‰
    if len(user_turns) <= 1:
        return True, "æ²¡æœ‰éœ€è¦æ£€æŸ¥çš„ user turns"
    
    # æ£€æŸ¥åç»­çš„ user turns
    for i, turn in enumerate(user_turns[1:], 1):  # ä»ç¬¬äºŒä¸ª user turn å¼€å§‹
        content = turn.get('content', '')
        
        if 'Tool result & environment status:' in content:
            tool_result = parse_tool_result(content)
            if tool_result:
                env_status = tool_result.get('Environment_status', '')
                if i-1 < len(security_type) and security_type[i-1] in env_info:
                    if env_status not in env_info[security_type[i-1]]:
                        return False, f"User turn {i+1} çš„ Environment_status ä¸ security_type[{i-1}] ä¸åŒ¹é…"
    
    return True, "æ‰€æœ‰ user turns çš„ Environment_status ä¸ security_type åŒ¹é…"

def check_chosen_rejected(sample, security_type):
    """
    æ£€æŸ¥ chosen å’Œ rejected å­—æ®µçš„åˆæ³•æ€§
    """
    errors = []
    
    chosen = sample.get('chosen', '')
    rejected = sample.get('rejected', '')
    
    if not chosen or not rejected:
        errors.append("chosen æˆ– rejected å­—æ®µä¸ºç©º")
        return errors
    
    # è·å–æœ€åä¸€ä¸ª security_type
    last_security_type = security_type[-1] if security_type else None
    
    if last_security_type == "Safe":
        # å¦‚æœæœ€åä¸€ä¸ª Security_type ä¸º "Safe"ï¼Œé‚£ä¹ˆ chosen åº”è¯¥æ˜¯æ­£å¸¸å›å¤
        if chosen.startswith("Unsafe MCP Server:"):
            errors.append("æœ€åä¸€ä¸ª security_type ä¸º 'Safe' æ—¶ï¼Œchosen ä¸åº”è¯¥æ˜¯æ‹’ç»å›å¤")
        
        # rejected å¯ä»¥æ˜¯æ‹’ç»å›å¤ï¼ˆå³æŠ¥é”™ Unsafe MCP Server:ï¼‰
        if not rejected.startswith("Unsafe MCP Server:"):
            errors.append("æœ€åä¸€ä¸ª security_type ä¸º 'Safe' æ—¶ï¼Œrejected åº”è¯¥æ˜¯æ‹’ç»å›å¤")
    
    else:
        # å¦‚æœæ˜¯å…¶ä»–çš„ riskï¼Œé‚£ä¹ˆ chosen åº”è¯¥æ˜¯æ‹’ç»å›å¤ä¸”æŠ¥é”™è¿™ä¸ª risk
        if not chosen.startswith("Unsafe MCP Server:"):
            errors.append(f"æœ€åä¸€ä¸ª security_type ä¸º '{last_security_type}' æ—¶ï¼Œchosen åº”è¯¥æ˜¯æ‹’ç»å›å¤")
        else:
            # æ£€æŸ¥ chosen ä¸­çš„ Reason æ˜¯å¦ä¸æœ€åä¸€ä¸ª security_type åŒ¹é…
            try:
                # è§£æ Unsafe MCP Server: åé¢çš„ JSON
                json_start = chosen.find("Unsafe MCP Server:") + len("Unsafe MCP Server:")
                chosen_json = json.loads(chosen[json_start:])
                chosen_reason = chosen_json.get('Reason', '')
                
                if chosen_reason != last_security_type:
                    errors.append(f"chosen ä¸­çš„ Reason '{chosen_reason}' ä¸æœ€åä¸€ä¸ª security_type '{last_security_type}' ä¸åŒ¹é…")
            except:
                errors.append("chosen ä¸­çš„ JSON æ ¼å¼ä¸æ­£ç¡®")
        
        # rejected å¯ä»¥æ˜¯æ­£å¸¸å›å¤æˆ–è€…æ‹’ç»å›å¤ä½†æ˜¯æŠ¥é”™å…¶ä»–ç±»åˆ«
        if rejected.startswith("Unsafe MCP Server:"):
            try:
                # è§£æ rejected ä¸­çš„ JSON
                json_start = rejected.find("Unsafe MCP Server:") + len("Unsafe MCP Server:")
                rejected_json = json.loads(rejected[json_start:])
                rejected_reason = rejected_json.get('Reason', '')
                
                # æ£€æŸ¥ rejected çš„ Reason æ˜¯å¦ä¸æœ€åä¸€ä¸ª security_type ä¸åŒ
                if rejected_reason == last_security_type:
                    errors.append(f"rejected ä¸­çš„ Reason '{rejected_reason}' ä¸åº”è¯¥ä¸æœ€åä¸€ä¸ª security_type '{last_security_type}' ç›¸åŒ")
            except:
                errors.append("rejected ä¸­çš„ JSON æ ¼å¼ä¸æ­£ç¡®")
    
    return errors

def check_single_sample(sample, sample_idx, env_info):
    """
    æ£€æŸ¥å•ä¸ªæ ·æœ¬çš„åˆæ³•æ€§
    """
    errors = []
    
    # 1. æ£€æŸ¥åŸºæœ¬ç»“æ„
    if not isinstance(sample, dict):
        errors.append("æ ·æœ¬ä¸æ˜¯æœ‰æ•ˆçš„å­—å…¸æ ¼å¼")
        return errors
    
    # 2. æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ['server_path', 'query', 'history', 'security_type', 'chosen', 'rejected']
    for field in required_fields:
        if field not in sample:
            errors.append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
    
    if errors:
        return errors
    
    # 3. æ£€æŸ¥ history çš„åˆæ³•æ€§ï¼ˆå‚è€ƒ curate_train_test.pyï¼‰
    history = sample.get('history', [])
    if not is_valid_response(history):
        errors.append("history æ ¼å¼ä¸åˆæ³•")
    
    # 4. æ£€æŸ¥ security_type çš„åˆæ³•æ€§ï¼ˆå‚è€ƒ Utils/utils.pyï¼‰
    security_type = sample.get('security_type', [])
    if not is_valid_security(security_type):
        errors.append("security_type æ ¼å¼ä¸åˆæ³•")
    
    # 5. æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥é£é™©
    if ignore_risk(security_type):
        errors.append("è¯¥æ ·æœ¬å¿½ç•¥äº†é£é™©ï¼ˆignore_risk è¿”å› Trueï¼‰")
    
    # 6. æ£€æŸ¥ security_type é•¿åº¦å’Œ history é•¿åº¦çš„å…³ç³»
    # å…¬å¼: 2*len(security_type) + 2 = len(history)
    expected_history_len = 2 * len(security_type) + 2
    actual_history_len = len(history)
    if actual_history_len != expected_history_len:
        errors.append(f"history é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {expected_history_len}, å®é™… {actual_history_len}")
    
    # 7. æ£€æŸ¥ security_type å’Œ Environment_status çš„åŒ¹é…
    match_result, match_message = check_security_type_environment_match(history, security_type, env_info)
    if not match_result:
        errors.append(match_message)
    
    # 8. æ£€æŸ¥ chosen å’Œ rejected å­—æ®µçš„åˆæ³•æ€§
    chosen_rejected_errors = check_chosen_rejected(sample, security_type)
    errors.extend(chosen_rejected_errors)
    
    return errors

def collect_statistics(file_path):
    """
    æ”¶é›†æ–‡ä»¶ä¸­çš„ç»Ÿè®¡ä¿¡æ¯
    """
    risk_counts = {}
    risk_observations = {}
    risk_observation_counts = {}  # æ–°å¢ï¼šç»Ÿè®¡æ¯ä¸ª observation çš„å‡ºç°æ¬¡æ•°
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():
                    try:
                        sample = json.loads(line)
                        security_type = sample.get('security_type', [])
                        
                        # ç»Ÿè®¡æ¯ä¸ª risk ç±»åˆ«çš„å‡ºç°æ¬¡æ•°
                        for risk in security_type:
                            risk_counts[risk] = risk_counts.get(risk, 0) + 1
                        
                        # æ”¶é›†æ¯ä¸ª risk ç±»åˆ«çš„ä¸åŒ observations
                        history = sample.get('history', [])
                        user_turns = [turn for turn in history if turn.get('role') == 'user']
                        
                        # è·³è¿‡ç¬¬ä¸€ä¸ª user turnï¼ˆåˆå§‹æŸ¥è¯¢ï¼‰
                        for i, turn in enumerate(user_turns[1:], 1):  # ä»ç¬¬äºŒä¸ª user turn å¼€å§‹
                            if i-1 < len(security_type):  # ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
                                risk = security_type[i-1]
                                content = turn.get('content', '')
                                
                                if 'Tool result & environment status:' in content:
                                    tool_result = parse_tool_result(content)
                                    if tool_result:
                                        env_status = tool_result.get('Environment_status', '')
                                        if risk not in risk_observations:
                                            risk_observations[risk] = set()
                                        risk_observations[risk].add(env_status)
                                        
                                        # ç»Ÿè®¡æ¯ä¸ª observation çš„å‡ºç°æ¬¡æ•°
                                        if risk not in risk_observation_counts:
                                            risk_observation_counts[risk] = {}
                                        if env_status not in risk_observation_counts[risk]:
                                            risk_observation_counts[risk][env_status] = 0
                                        risk_observation_counts[risk][env_status] += 1
                        
                    except json.JSONDecodeError:
                        continue
    
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return {}, {}, {}
    
    return risk_counts, risk_observations, risk_observation_counts

def print_statistics(file_path, risk_counts, risk_observations, risk_observation_counts):
    """
    æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"\nğŸ“Š {file_path} ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 50)
    
    # æŒ‰é£é™©ç±»å‹æ’åº
    sorted_risks = sorted(risk_counts.keys())
    
    for risk in sorted_risks:
        count = risk_counts[risk]
        unique_obs = len(risk_observations.get(risk, set()))
        print(f"{risk}: {count} æ¬¡, {unique_obs} ç§ä¸åŒ observations")
    
    print("-" * 50)
    print(f"æ€»è®¡: {sum(risk_counts.values())} ä¸ªæ ·æœ¬")
    
    # ç»Ÿè®¡æ‰€æœ‰ observation çš„å‡ºç°æ¬¡æ•°ï¼Œå¹¶è¾“å‡ºæœ€å¤§å€¼ã€æœ€å°å€¼ã€ä¸­ä½æ•°å’Œå¹³å‡æ•°
    all_observation_counts = []
    for risk, obs_counts in risk_observation_counts.items():
        all_observation_counts.extend(obs_counts.values())
    
    if all_observation_counts:
        max_count = max(all_observation_counts)
        min_count = min(all_observation_counts)
        median_count = statistics.median(all_observation_counts)
        mean_count = statistics.mean(all_observation_counts)
        print(f"Observation å‡ºç°æ¬¡æ•° - æœ€å¤§å€¼: {max_count}, æœ€å°å€¼: {min_count}, ä¸­ä½æ•°: {median_count:.2f}, å¹³å‡æ•°: {mean_count:.2f}")
    else:
        print("æœªæ‰¾åˆ°ä»»ä½• observation æ•°æ®")

def check_observation_overlap(train_observations, test_observations):
    """
    æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„ observations é‡å æƒ…å†µ
    """
    print(f"\nğŸ” æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„ observations é‡å æƒ…å†µ:")
    print("-" * 60)
    
    # è·å–æ‰€æœ‰é£é™©ç±»å‹
    all_risks = set(train_observations.keys()) | set(test_observations.keys())
    sorted_risks = sorted(all_risks)
    
    total_overlaps = 0
    total_train_obs = 0
    total_test_obs = 0
    
    for risk in sorted_risks:
        train_obs = train_observations.get(risk, set())
        test_obs = test_observations.get(risk, set())
        
        # è®¡ç®—é‡å 
        overlap = train_obs & test_obs
        overlap_count = len(overlap)
        
        train_count = len(train_obs)
        test_count = len(test_obs)
        
        total_overlaps += overlap_count
        total_train_obs += train_count
        total_test_obs += test_count
        
        if train_count > 0 or test_count > 0:
            overlap_percentage = (overlap_count / max(train_count, test_count)) * 100 if max(train_count, test_count) > 0 else 0
            print(f"{risk}:")
            print(f"  è®­ç»ƒé›†: {train_count} ç§ observations")
            print(f"  æµ‹è¯•é›†: {test_count} ç§ observations")
            print(f"  é‡å : {overlap_count} ç§ ({overlap_percentage:.1f}%)")
            
            if overlap_count > 0:
                print(f"  âš ï¸  å‘ç° {overlap_count} ä¸ªé‡å çš„ observations")
            else:
                print(f"  âœ… æ— é‡å ")
            print()
    
    # æ€»ä½“ç»Ÿè®¡
    print("-" * 60)
    print(f"æ€»ä½“ç»Ÿè®¡:")
    print(f"è®­ç»ƒé›†æ€» observations: {total_train_obs}")
    print(f"æµ‹è¯•é›†æ€» observations: {total_test_obs}")
    print(f"æ€»é‡å æ•°: {total_overlaps}")
    
    if total_overlaps > 0:
        max_obs = max(total_train_obs, total_test_obs)
        overall_overlap_percentage = (total_overlaps / max_obs) * 100 if max_obs > 0 else 0
        print(f"æ€»ä½“é‡å ç‡: {overall_overlap_percentage:.1f}%")
        print(f"âš ï¸  è­¦å‘Š: å‘ç° {total_overlaps} ä¸ªé‡å çš„ observationsï¼Œå¯èƒ½å­˜åœ¨æ•°æ®æ³„éœ²é£é™©ï¼")
    else:
        print(f"âœ… æ— é‡å ï¼Œæ•°æ®åˆ†ç¦»è‰¯å¥½")
    
    print("-" * 60)
    
    return total_overlaps

def check_file(file_path, env_info):
    """
    æ£€æŸ¥å•ä¸ªæ–‡ä»¶
    """
    print(f"æ£€æŸ¥æ–‡ä»¶: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    
    errors_count = 0
    total_samples = 0
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():
                    try:
                        sample = json.loads(line)
                        total_samples += 1
                        
                        errors = check_single_sample(sample, total_samples, env_info)
                        if errors:
                            print(f"âŒ æ ·æœ¬ {total_samples} (è¡Œ {line_num}) æœ‰é”™è¯¯:")
                            for error in errors:
                                print(f"   - {error}")
                            errors_count += 1
                        
                    except json.JSONDecodeError as e:
                        print(f"âŒ è¡Œ {line_num} JSON è§£æé”™è¯¯: {e}")
                        errors_count += 1
                        total_samples += 1
    
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False
    
    print(f"âœ… æ–‡ä»¶æ£€æŸ¥å®Œæˆ: {total_samples} ä¸ªæ ·æœ¬, {errors_count} ä¸ªé”™è¯¯")
    return errors_count == 0

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 60)
    print("æ•°æ®åˆæ³•æ€§æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    
    # åŠ è½½ç¯å¢ƒä¿¡æ¯
    print("åŠ è½½ç¯å¢ƒä¿¡æ¯...")
    env_info = load_env_info()
    if env_info is None:
        print("é”™è¯¯ï¼šæ— æ³•åŠ è½½ç¯å¢ƒä¿¡æ¯ï¼Œé€€å‡º")
        return False
    
    # æ£€æŸ¥çš„æ–‡ä»¶åˆ—è¡¨
    files_to_check = [
        "env_data_train.jsonl",
        "env_data_test.jsonl"
    ]
    
    all_passed = True
    all_risk_counts = {}
    all_risk_observations = {}
    train_observations = {}
    test_observations = {}
    
    for file_path in files_to_check:
        print(f"\n{'='*40}")
        
        # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
        risk_counts, risk_observations, risk_observation_counts = collect_statistics(file_path)
        
        # åˆå¹¶åˆ°æ€»ç»Ÿè®¡ä¸­
        for risk, count in risk_counts.items():
            all_risk_counts[risk] = all_risk_counts.get(risk, 0) + count
        
        for risk, observations in risk_observations.items():
            if risk not in all_risk_observations:
                all_risk_observations[risk] = set()
            all_risk_observations[risk].update(observations)
        
        # åˆ†åˆ«ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ observations
        if "train" in file_path:
            train_observations = risk_observations
        elif "test" in file_path:
            test_observations = risk_observations
        
        # æ‰“å°å•ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
        print_statistics(file_path, risk_counts, risk_observations, risk_observation_counts)
        
        # æ£€æŸ¥æ–‡ä»¶
        if not check_file(file_path, env_info):
            all_passed = False
        print(f"{'='*40}")
    
    # æ£€æŸ¥ observations é‡å æƒ…å†µ
    if train_observations and test_observations:
        overlap_count = check_observation_overlap(train_observations, test_observations)
        if overlap_count > 0:
            all_passed = False  # å¦‚æœæœ‰é‡å ï¼Œæ ‡è®°ä¸ºæ£€æŸ¥å¤±è´¥
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print("ğŸ“Š æ€»ä½“ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 50)
    
    # æŒ‰é£é™©ç±»å‹æ’åº
    sorted_risks = sorted(all_risk_counts.keys())
    
    for risk in sorted_risks:
        count = all_risk_counts[risk]
        unique_obs = len(all_risk_observations.get(risk, set()))
        print(f"{risk}: {count} æ¬¡, {unique_obs} ç§ä¸åŒ observations")
    
    print("-" * 50)
    print(f"æ€»è®¡: {sum(all_risk_counts.values())} ä¸ªæ ·æœ¬")
    print(f"{'='*60}")
    
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶æ£€æŸ¥é€šè¿‡ï¼")
    else:
        print("âŒ éƒ¨åˆ†æ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    print(f"{'='*60}")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
