# Pipeline.py 使用说明

## 概述

`pipeline.py` 是一个自动化模型评估流水线，用于为不同的LLM模型生成history并评估其质量。

## 功能特性

### 🚀 自动化流程
1. **History生成**: 调用 `history_generator.py` 为数据生成history
2. **质量评估**: 调用评估器评估所产生的history的质量
3. **多模型支持**: 支持7个不同的模型

### 📊 进度监控
- **实时进度显示**: 显示history生成的详细进度
- **文件大小监控**: 实时监控输出文件的大小变化
- **状态更新**: 显示处理状态和预估剩余时间

## 使用方法

### 基本用法

```bash
# 使用默认设置运行所有模型
python pipeline.py

# 启用详细进度监控
python pipeline.py --show-progress

# 指定并发工作线程数
python pipeline.py --max-workers 100

# 启用调试模式
python pipeline.py --debug

# 只处理特定模型
python pipeline.py --models gpt-4o claude-3-5-sonnet-20241022
```

### 命令行参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--max-workers` | int | 50 | 最大并发工作线程数 |
| `--debug` | flag | False | 启用调试模式 |
| `--models` | list | 所有模型 | 指定要处理的模型列表 |
| `--show-progress` | flag | False | 启用详细进度监控 |

## 输出文件

### 结果文件
- `results_{model}.json`: 每个模型的评估结果
- `pipeline_summary.json`: 整个流水线的总结报告

### History文件
- `histories_prin_{model}.jsonl`: PRIN数据的history文件
- `histories_env_{model}.jsonl`: ENV数据的history文件

## 进度显示说明

### History生成进度
- 📊 **查询总数**: 显示输入文件中的总查询数量
- 📈 **完成进度**: 显示已完成的查询数量和百分比
- 💾 **文件大小**: 每15秒显示输出文件的当前大小
- ⏱️ **时间统计**: 显示已用时间和预估剩余时间

### 状态更新
- 🔄 **当前步骤**: 显示正在执行的步骤
- 📋 **整体进度**: 显示模型处理进度
- ⚠️ **警告信息**: 显示跳过的查询和警告
- ❌ **错误信息**: 显示处理失败的错误

## 注意事项

1. **环境配置**: 确保 `.env` 文件正确配置
2. **磁盘空间**: 确保有足够的磁盘空间存储输出文件
3. **网络连接**: 确保API服务可访问
4. **权限设置**: 确保有读写输出目录的权限

## 故障排除

### 常见问题

1. **文件未找到错误**
   - 检查数据文件路径是否正确
   - 确认系统提示文件存在

2. **权限错误**
   - 检查输出目录的写入权限
   - 确认.env文件的读写权限

3. **API错误**
   - 检查网络连接
   - 验证API密钥和配置

4. **没有生成中间结果**
   - 检查输出目录是否存在
   - 确认文件是否正常创建
   - 查看控制台输出的错误信息

## 扩展功能

### 自定义模型
可以在 `MODELS` 列表中添加新的模型名称

### 自定义数据源
可以修改 `DATA_FILES` 字典来使用不同的输入文件
